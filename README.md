ğŸ“ƒ Seminar
===========
Top Conferences ë°œí‘œëœ ë…¼ë¬¸ì„ ë§¤ì£¼ í•œ ëª…ì˜ ë°œí‘œìê°€ ë°œí‘œë¥¼ ì§„í–‰í•˜ëŠ” ì„¸ë¯¸ë‚˜ì…ë‹ˆë‹¤. 
<br><br>


|ë‚ ì§œ|ì œëª©|ë°œí–‰ ë…„ë„|Venue|ë°œí‘œì|
|----|----|----|----|----|
|220729|[Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing](https://arxiv.org/pdf/2107.13586.pdf)|2021-07-28||ì•ˆì œì¤€|
|220603|[Vision-Language Pretraining:Current Trends and the Future](https://aclanthology.org/2022.acl-tutorials.7.pdf)|2022-05-22|ACL tutorial|ìœ¤ì˜ˆì¤€|
|220603|[Knowledge-Augmented Methods for Natural Language Processing](https://aclanthology.org/2022.acl-tutorials.3.pdf)|2022-05-22|ACL tutorial|ì•ˆì œì¤€|
|220603|[Learning with Limited Text Data](https://aclanthology.org/2022.acl-tutorials.5.pdf)|2022-05-22|ACL tutorial|ë°•ì‚°ì•¼|
|220520|[Deep contextualized word representations](https://aclanthology.org/2022.acl-tutorials.7.pdf)|2018-03-22|NAACL|ì†¡ì„ ì˜|
|220513|[ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators](https://openreview.net/pdf?id=r1xMH1BtvB)|2020-03-23|ICLR|ë°•ì±„ì›|
|220506|[Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165.pdf)|2020-07-22|OpenAI|ìœ¤ì˜ˆì¤€|
|220412|[Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)|2019-08-28|OpenAI|ì†¡ì„ ì˜|
|220405|[Improving Language Understanding by Generative Pre-Training](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)|2018-06-11|OpenAI|ë°•ì±„ì›|
|220329|[Longformer: The Long-Document Transformer](https://arxiv.org/pdf/2004.05150.pdf)|2020-12-02||ìµœí˜œì›|
|220322|[Learning Phrase Representations using RNN Encoderâ€“Decoder for Statistical Machine Translation](https://arxiv.org/pdf/1406.1078.pdf)|2014-09-03|EMNLP|ìœ¤ì˜ˆì¤€|
|220315|[A Survey on Recent Approaches for Natural Language Processing in Low-Resource Scenarios](https://aclanthology.org/2021.naacl-main.201.pdf)|2021-04-09|NAACL|ì†¡ì„ ì˜|
|220308|[EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks](https://aclanthology.org/D19-1670.pdf)|2019-08-25|EMNLP|ë°•ì±„ì›|
|211105|[Automatic Identification of Harmful, Aggressive, Abusive, and Offensive Language on the Web : A Survey of Technical Biases Informed by Psychology Literature](https://dl.acm.org/doi/pdf/10.1145/3479158)|2021-10-25|ACM|ë°•ì±„ì›,ì´ìƒìœ¤|
|211001|[What Changes Can Large-scale Language Models Bring? Intensive Study on HyperCLOVA: Billions-scale Korean Generative Pretrained Transformers](https://arxiv.org/pdf/2109.04650.pdf)|2021-09-10|EMNLP|ì†¡ì„ ì˜|
|210910|Model Compression|||ìµœí˜œì›|
|210910|[Rich feature hierarchies for accurate object detection and semantic segmentation](https://arxiv.org/pdf/1311.2524.pdf)|2014-10-22|CVPR|ê¹€íƒœìš°|
|210827|[Learning from the Worst: Dynamically Genearated Datasets to improve Online Hate Detection!](https://arxiv.org/pdf/2012.15761v2.pdf)|2021-06-03|ACL|ë°•ì±„ì›|
|210820|[Assessing Emoji Use in Modern Text Processing Tools](https://aclanthology.org/2021.acl-long.110v2.pdf)|2021-01-02|ACL|ì†¡ì„ ì˜|
|210813|[Changes in European Solidarity Before and During COVID-19: Evidence from a Large Crowd- and Expert-Annotated Twitter Dataset](https://arxiv.org/pdf/2108.01042.pdf)|2021-08-02|ACL|ìµœí˜œì›|
|210806|[Ruddit: Norms of Offensiveness for English Reddit Comments](https://arxiv.org/pdf/2106.05664.pdf)|2021-06-11|ACL|ìœ¤ì˜ˆì¤€|
|210730|[HATECHECK: Functional Tests for Hate Speech Detection Models](https://aclanthology.org/2021.acl-long.4.pdf)|2021-05-27|ACL|ì´ìƒìœ¤|
